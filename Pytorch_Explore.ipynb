{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "uniform-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "#MNIST data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f914456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local functions\n",
    "from data.load_data import load_mnist_data\n",
    "from data.my_dataset import MyDataset\n",
    "#Classifiers\n",
    "from src.models import Digit_Classifier\n",
    "from src.models import Dog_Classifier_FC\n",
    "from src.models import Dog_Classifier_Conv\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b166d",
   "metadata": {},
   "source": [
    "## Training on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8987c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in data\n",
    "training_sizes = [500, 1000, 1500, 2000]\n",
    "#for size in training_sizes:\n",
    "size = 500\n",
    "tr_f, te_f, tr_t, te_t = load_mnist_data(10, 1, size/10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e9c1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 500,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e64d135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = MyDataset(tr_f, tr_t)\n",
    "training_generator = DataLoader(trainingset, **params)\n",
    "\n",
    "#useless bc testing set empty\n",
    "testingset = MyDataset(te_f, te_t)\n",
    "testing_generator = DataLoader(testingset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27b8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(training_generator) = 50 mini batches of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd9cc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testingset = MyDataset(te_f, te_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba891283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393dc8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f30e901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3136e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_cuda = torch.cuda.is_available()\n",
    "#device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf15d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53671ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, trainloader, idx, optimizer, model, criterion):\n",
    "    for local_batch, local_labels in trainloader:\n",
    "        #optionally send to gpu/cpu\n",
    "        #local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "        \n",
    "        #stupid line\n",
    "        local_batch = local_batch.float(); local_labels = local_labels.long()\n",
    "\n",
    "        #X = local_batch (10,784), Y = batch labels (10,)\n",
    "        \n",
    "        #zero grads\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward, backward, optimize\n",
    "        y_hat = model(local_batch)\n",
    "        loss = criterion(y_hat, local_labels)\n",
    "        \n",
    "        #record loss\n",
    "        losses[idx, epoch] = loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "#assertion errors / warnings? when workers > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682e1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(idx, testloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.float(); labels = labels.long()\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the 1000 test images: %d %%' % (100 * correct / total))\n",
    "    \n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b552c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a time\n",
    "def run_epochs(idx, dataloader_obj, opt, model, cri):\n",
    "    start = time.time()\n",
    "    for epoch in range(100):\n",
    "        train(epoch, dataloader_obj, idx, opt, model, cri)\n",
    "    end = time.time()\n",
    "    \n",
    "    return end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b8fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hoppers\n",
    "losses = np.empty((4, 100))\n",
    "training_sizes = [500, 1000, 1500, 2000]\n",
    "models = [None]*4\n",
    "time_elapsed = [None]*4 #in seconds\n",
    "accuracies = [None]*4 #in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e77e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_mnist():\n",
    "    for idx, size in enumerate(training_sizes):\n",
    "        #load in training data\n",
    "        tr_f, _, tr_t, _ = load_mnist_data(10, 1, size/10)\n",
    "        \n",
    "        #make DataLoaders for training\n",
    "        trainingset = MyDataset(tr_f, tr_t)\n",
    "        training_generator = DataLoader(trainingset, **params)\n",
    "        \n",
    "        #init our classifier, loss, and optimizer\n",
    "        models[idx] = Digit_Classifier()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(models[idx].parameters(), lr=0.01)\n",
    "        \n",
    "        #run 100 epoch loop & record time\n",
    "        time_elapsed[idx] = run_epochs(idx, training_generator, optimizer, models[idx], criterion)\n",
    "        \n",
    "        #evaluate accuracy on testing set\n",
    "        accuracies[idx] = test(idx, testing_generator, models[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ad041d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing set + DataLoader\n",
    "_, te_f, _, te_t = load_mnist_data(10, 0, 100)\n",
    "testingset = MyDataset(te_f, te_t)\n",
    "testing_generator = DataLoader(testingset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adbe1ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 14 %\n",
      "Accuracy of the network on the 1000 test images: 28 %\n",
      "Accuracy of the network on the 1000 test images: 46 %\n",
      "Accuracy of the network on the 1000 test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "train_on_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d9f4196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41965556144714355,\n",
       " 0.8396413326263428,\n",
       " 1.4331097602844238,\n",
       " 1.6884040832519531]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3226c5eb",
   "metadata": {},
   "source": [
    "### 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e3077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fadd04942e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(training_sizes, time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a66f02",
   "metadata": {},
   "source": [
    "### 1-2\n",
    "Training time increases linearly with the number of training examples. To train the full MNIST training set of 60K images, it would take (60K/2K)*10seconds/60min/hr = 5hrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1bc5fc",
   "metadata": {},
   "source": [
    "### 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7ab4c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fadd039bfd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAASw0lEQVR4nO3df5BdZ33f8fenWmGtlGKJekmQgEoEEOOhCaYbRjVJ01guorQTaaZ0ojZuSFKPp3RSN2pHKSqdatJpZprIQ2aSacOoBfrLFbhCKExbKpEfbdKZIrpItiVhBCJKhFeiLE0kN8mGyPa3f9yzZr2svHftvbv30b5fM3f27HPO8f3M470f3fvcc3dTVUiS2vMnVjqAJOnFscAlqVEWuCQ1ygKXpEZZ4JLUqJHlvLM77rijtm7dupx3KUnN+9znPvf1qhqbO76sBb5161YmJiaW8y4lqXlJfme+cZdQJKlRFrgkNcoCl6RGWeCS1CgLXJIataxXoUjSanL8zCSHTlzgyrVpNm8cZf+u7ey5a8uS/fctcEkagONnJjlw7CzTN54BYPLaNAeOnQVYshJ3CUWSBuDQiQvPlfeM6RvPcOjEhSW7DwtckgbgyrXpRY2/GBa4JA3A5o2jixp/MSxwSRqA/bu2M7p2zfPGRteuYf+u7Ut2H76JKUkDMPNGpVehSFKD9ty1ZUkLey6XUCSpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJalRfBZ5kX5LzSc4lOZJkXZKdSU4neTTJ/0zy+kGHlSR904IFnmQL8CAwXlVvBtYAe4FfAn64qt4C/EfgHw8wpyRpjn6XUEaA0SQjwHrgClDAy7v9t3djkqRlsuBH6atqMslDwGVgGjhZVSeT3A/81yTTwFPAjvnOT/IA8ADAa1/72iULLkmrXT9LKJuA3cA2YDOwIcl9wD7gXVX1auAjwAfmO7+qDlfVeFWNj42NLV1ySVrl+llCuRe4VFVTVXUDOAa8HfjuqjrVHfMx4O4BZZQkzaOfAr8M7EiyPkmAncDngduTvLE75i8CTwwooyRpHv2sgZ9KchQ4DTwNnAEOA08CH0/yLPB7wI8PMqgk6fn6+n3gVXUQODhn+BPdTZK0AvwkpiQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGtVXgSfZl+R8knNJjiRZl+Q3kzza3a4kOT7grJKkWRb8q/RJtgAPAndW1XSSR4C9VfV9s475OPDLg4spSZqr3yWUEWA0yQiwHrgysyPJy4F7gONLnk6SdFMLFnhVTQIPAZeBq8D1qjo565A9wK9W1VPznZ/kgSQTSSampqaWILIkCfoo8CSbgN3ANmAzsCHJfbMO+evAkZudX1WHq2q8qsbHxsZeal5JUqefJZR7gUtVNVVVN4BjwN0ASe4A3gb8l8FFlCTNp58CvwzsSLI+SYCdwBPdvncD/7mq/mhQASVJ8+tnDfwUcBQ4DZztzjnc7d7LCyyfSJIGZ8HLCAGq6iBwcJ7xv7DUgSRJ/fGTmJLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmN6qvAk+xLcj7JuSRHkqxLz88k+WKSJ5I8OOiwkqRvGlnogCRbgAeBO6tqOskjwF4gwGuAN1XVs0leOdiokqTZFizwWceNJrkBrAeuAP8M+BtV9SxAVX1tMBElSfNZcAmlqiaBh4DLwFXgelWdBL4T+KEkE0k+leQN852f5IHumImpqamlzC5Jq9qCBZ5kE7Ab2AZsBjYkuQ+4DfijqhoH/hXw4fnOr6rDVTVeVeNjY2NLl1ySVrl+3sS8F7hUVVNVdQM4BtwNPNltA3wC+K7BRJQkzaefNfDLwI4k64FpYCcwATwF/ABwCfh+4IuDCilpYcfPTHLoxAWuXJtm88ZR9u/azp67tqx0LA3QggVeVaeSHAVOA08DZ4DDwCjwcJJ9wO8D9w8yqKSbO35mkgPHzjJ94xkAJq9Nc+DYWQBL/BbW11UoVXUQODhn+BvAX17yRJIW7dCJC8+V94zpG89w6MQFC/wW5icxpVvAlWvTixrXrcECl24BmzeOLmpctwYLXLoF7N+1ndG1a543Nrp2Dft3bV+hRFoO/X4SU9IQm1nn9iqU1cUCl24Re+7aYmGvMi6hSFKjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1Ki+CjzJviTnk5xLciTJuiT/JsmlJI92t7cMOKskaZYF/6BDki3Ag8CdVTWd5BFgb7d7f1UdHWRASdL8+l1CGQFGk4wA64Erg4skSerHggVeVZPAQ8Bl4CpwvapOdrt/JsnjSX4+yW0DzClJmmPBAk+yCdgNbAM2AxuS3AccAN4EfA/wCuAf3uT8B5JMJJmYmppasuCStNr1s4RyL3Cpqqaq6gZwDLi7qq5WzzeAjwBvm+/kqjpcVeNVNT42NrZ0ySVpleunwC8DO5KsTxJgJ/BEklcBdGN7gHMDSylJ+hYLXoVSVaeSHAVOA08DZ4DDwKeSjAEBHgX+9gBzSpLmWLDAAarqIHBwzvA9Sx9HktQvP4kpSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1Ki+CjzJviTnk5xLciTJuln7fiHJ7w8uoiRpPgsWeJItwIPAeFW9GVgD7O32jQObBppQkjSvfpdQRoDRJCPAeuBKkjXAIeCnBhVOknRzCxZ4VU0CDwGXgavA9ao6CfwE8MmquvpC5yd5IMlEkompqamlyCxJor8llE3AbmAbsBnYkORHgL8G/OJC51fV4aoar6rxsbGxl5pXktQZ6eOYe4FLVTUFkOQY8NPAKHAxCcD6JBer6vUDSypJep5+1sAvAzuSrE+vrXcCH6iq76iqrVW1FfhDy1uSllc/a+CngKPAaeBsd87hAeeSJC2gnyUUquogcPAF9n/bkiWSJPXFT2JKUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1Kj+vokpjTb8TOTHDpxgSvXptm8cZT9u7az564tKx1LWnUscC3K8TOTHDh2lukbzwAweW2aA8fOAlji0jJzCUWLcujEhefKe8b0jWc4dOLCCiWSVi8LXIty5dr0osYlDY4FrkXZvHF0UeOSBscC16Ls37Wd0bVrnjc2unYN+3dtX6FE0urlm5halJk3Kr0KRVp5FrgWbc9dWyxsaQi4hCJJjbLAJalRFrgkNaqvAk+yL8n5JOeSHEmyLsmHkjyW5PEkR5P4h40laRktWOBJtgAPAuNV9WZgDbAX2FdV311V3wVcBn5ioEklSc/T7xLKCDCaZARYD1ypqqcAkgQYBWowESVJ81mwwKtqEniI3rPsq8D1qjoJkOQjwFeBNwG/OMCckqQ5+llC2QTsBrYBm4ENSe4DqKof68aeAH7oJuc/kGQiycTU1NSSBZek1a6fJZR7gUtVNVVVN4BjwN0zO6vqGeCjwF+d7+SqOlxV41U1PjY2thSZJUn0V+CXgR1J1nfr3TuBJ5K8Hp5bA/9B4AuDiylJmmvBj9JX1akkR4HTwNPAGeAw8GtJXg4EeAx47yCDSpKer6/fhVJVB4GDc4bfvvRxJEn98pOYktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY3qq8CT7EtyPsm5JEeSrEvycJIL3diHk6wddFhJ0jctWOBJtgAPAuNV9WZgDbAXeBh4E/BngFHg/gHmlCTNMbKI40aT3ADWA1eq6uTMziSfBV49gHySpJtY8Bl4VU0CDwGXgavA9TnlvRb4m8B/m+/8JA8kmUgyMTU1tTSpJUl9LaFsAnYD24DNwIYk98065F8Cv1FVvznf+VV1uKrGq2p8bGxsKTJLkujvTcx7gUtVNVVVN4BjwN0ASQ4CY8DfH1xESdJ8+lkDvwzsSLIemAZ2AhNJ7gd2ATur6tlBBTx+ZpJDJy5w5do0mzeOsn/XdvbctWVQdydJzViwwKvqVJKjwGngaeAMcBj4A+B3gP+VBOBYVf3TpQx3/MwkB46dZfrGMwBMXpvmwLGzAJa4pFWvr6tQquogcPDFnPtSHDpx4bnynjF94xkOnbhggUta9Yb6k5hXrk0valySVpOhLvDNG0cXNS5Jq8lQF/j+XdsZXbvmeWOja9ewf9f2FUokScNj4OvYL8XMOrdXoUjStxrqAodeiVvYkvSthnoJRZJ0cxa4JDXKApekRlngktQoC1ySGpWqWr47S6bo/f6UYXAH8PWVDrGAYc847PnAjEth2PPB8Gd8qfn+dFV9y+/jXtYCHyZJJqpqfKVzvJBhzzjs+cCMS2HY88HwZxxUPpdQJKlRFrgkNWo1F/jhlQ7Qh2HPOOz5wIxLYdjzwfBnHEi+VbsGLkmtW83PwCWpaRa4JDXqli7wJBuTHE3yhSRPJPlzSV6R5NNJvtR93dQdmyS/kORikseTvHUZ8u1Lcj7JuSRHkqxLsi3JqS7Hx5K8rDv2tu77i93+rQPK9OEkX0tybtbYoucsyXu647+U5D3LkPFQ9//58SSfSLJx1r4DXcYLSXbNGn9nN3YxyfsGmW/Wvn+QpJLc0X0/NHPYjf/dbh7PJ/m5WeMrPodJ3pLkM0keTTKR5G3d+ErN4WuS/HqSz3fz9fe68eV7vFTVLXsD/i1wf7f9MmAj8HPA+7qx9wE/222/C/gUEGAHcGrA2bYAl4DR7vtHgB/tvu7txj4IvLfb/jvAB7vtvcDHBpTrzwNvBc7NGlvUnAGvAH6r+7qp29404IzvAEa67Z+dlfFO4DHgNmAb8GVgTXf7MvC67mfjMeDOQeXrxl8DnKD3YbY7hnAOfwD4FeC27vtXDtMcAieBvzRr3v77Cs/hq4C3dtt/EvhiN1fL9ni5ZZ+BJ7md3g/BhwCq6o+r6hqwm16x033d023vBv5d9XwG2JjkVQOOOQKMJhkB1gNXgXuAozfJN5P7KLAzSZY6UFX9BvC7c4YXO2e7gE9X1e9W1e8BnwbeOciMVXWyqp7uvv0M8OpZGT9aVd+oqkvAReBt3e1iVf1WVf0x8NHu2IHk6/w88FPA7CsHhmYOgfcC/7yqvtEd87VZGYdhDgt4ebd9O3BlVr6VmMOrVXW62/5/wBP0npgt2+Plli1wes8UpoCPJDmT5F8n2QB8e1Vd7Y75KvDt3fYW4Cuzzn+yGxuIqpoEHgIu0yvu68DngGuzimh2hufydfuvA39qUPnmWOycLetczuPH6T3T4QWyLGvGJLuByap6bM6uocjXeSPwfd0S3f9I8j1DlvEngUNJvkLvsXNgWPKlt6R5F3CKZXy83MoFPkLvJdgvVdVdwB/QeznznOq9flmR6yi7dbHd9P6h2QxsYAmfHQzKSs5ZP5K8H3gaeHils8xIsh74R8A/WeksCxih9zJ+B7AfeGQQr/JegvcC+6rqNcA+ulfXKy3JtwEfB36yqp6avW/Qj5dbucCfBJ6sqlPd90fpFfr/mVka6b7OvEycpLdGOePV3dig3AtcqqqpqroBHAPeTu9l1cyfupud4bl83f7bgf87wHyzLXbOlnsu6bL9KPBXgB/uHjjDkvE76f1D/ViS3+7u63SS7xiSfDOeBI51L/E/CzxL75cwDUvG99B7nAD8J3pLOKxkviRr6ZX3w1U1k23ZHi+3bIFX1VeBrySZ+RP2O4HPA5+k94NA9/WXu+1PAj/SvVO8A7g+62XQIFwGdiRZ3z3Lmcn368C7b5JvJve7gV+bVVKDttg5OwG8I8mm7pXGO7qxgUnyTnrryz9YVX84J/ve9K7i2Qa8Afgs8L+BN6R31c/L6L0x/MlBZKuqs1X1yqraWlVb6RXlW7uf0aGZQ+A4vTcySfJGem9Mfp0hmMPOFeD7u+17gC912ysyh93j9kPAE1X1gVm7lu/xshTvxg7rDXgLMAE8Tu+HcxO9deNfpfc//1eAV3THBvgX9N5VPwuML0O+nwa+AJwD/j29d/lfR+/BcZHes4yZKwLWdd9f7Pa/bkCZjtBbk79Br2j+1ouZM3rr0Be7248tQ8aL9NYRH+1uH5x1/Pu7jBformLoxt9F78qBLwPvH2S+Oft/m29ehTJMc/gy4D90P4+ngXuGaQ6B76X3PtFj9Naa/+wKz+H30lseeXzWz927lvPx4kfpJalRt+wSiiTd6ixwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1Kj/Dy4nkayoEjCoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(training_sizes, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b06da9",
   "metadata": {},
   "source": [
    "### 1-4\n",
    "The training accuracy pretty much also increases linearly wrt number of training examples. Though This would mean that very soon the model will have a very high accuracy and probably this is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d055fa1",
   "metadata": {},
   "source": [
    "## Exploring DogSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aeae5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dogs import DogsDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55540799",
   "metadata": {},
   "source": [
    "### 5\n",
    "7665 in train, 555 in test, 2000 in valid partition, 3 color channels, and 10 dog breeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41a87a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train...\n",
      "loading valid...\n",
      "loading test...\n"
     ]
    }
   ],
   "source": [
    "todogs = DogsDataset('data/DogSet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9da54f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 64, 64, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todogs.get_validation_examples()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967e5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fedf8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af6412e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    l[-1]\n",
    "except IndexError as e:\n",
    "    print(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ceeb7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6e75047",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "824a522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d126a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "hehe\n",
      "1\n",
      "hehe\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    if i < 2:\n",
    "        print(i)\n",
    "        print('hehe')\n",
    "        pass\n",
    "    elif l[-1] > l[-2]:\n",
    "        print(i)\n",
    "        break\n",
    "    l.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43863bef",
   "metadata": {},
   "source": [
    "## Convolutional layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca756211",
   "metadata": {},
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca213eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels = 16\n",
    "kernel_size = (5,5)\n",
    "stride = (1, 1)\n",
    "conv2d1 = nn.Conv2d(in_channels, out_channels, \n",
    "                   kernel_size, stride=stride, \n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce224de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.Tensor(0.1 * np.ones((1,64,64,3)))\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ccf272",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 3, 5, 5], expected input[1, 64, 64, 3] to have 3 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c8f34d4e551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ml349/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml349/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml349/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 3, 5, 5], expected input[1, 64, 64, 3] to have 3 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "out = conv2d1(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4a81c3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 28, 28])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6e765f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = F.max_pool2d(F.relu(conv2d1(inputs)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "81cbb8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 14, 14])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "98b3de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 16\n",
    "out_channels = 32\n",
    "kernel_size = (5, 5)\n",
    "stride = (1, 1)\n",
    "conv2d2 = nn.Conv2d(in_channels, out_channels, \n",
    "                   kernel_size, stride=stride, \n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ae40e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = F.max_pool2d(F.relu(conv2d2(inputs)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c1b3c66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 5, 5])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "75200831",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc3 = nn.Linear(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a6cf8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = fc3(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4df2b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 5, 10])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e3bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3140b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d209d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e9683c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins = torch.rand(3,64,64).view(-1, 3, 64, 64)\n",
    "ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec2b9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = nn.Conv2d(3, 16, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8f03f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = nn.Conv2d(16, 32, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b35eb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 30, 30])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins = F.max_pool2d(F.relu(c1(ins)), 2)\n",
    "ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55e6ad30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 13, 13])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins = F.max_pool2d(F.relu(c2(ins)), 2)\n",
    "ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4de3914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc3 = nn.Linear(13, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2158f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 13, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins = fc3(ins)\n",
    "ins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd2f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35268808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08635cb5",
   "metadata": {},
   "source": [
    "Input to conv2d:\n",
    "(batchsize, channels, height, width)\n",
    "Output:\n",
    "(batchsize, channels_out, height_out, width_out) for outs based on documentation math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124b8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7423c511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2, 1])\n",
      "torch.Size([4, 3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,2,3,4)\n",
    "print(a.transpose(0,3).transpose(1,2).size())\n",
    "print(a.permute(3,2,1,0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "367f163c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape\n",
    "a = torch.transpose(a, 2, 3).shape\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77fbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90d8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0905ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
